# ğŸ® Grumpy Gamer

> **Teaching AI to rage-quit less than humans** *(eventually)*

<div align="center">

![Status](https://img.shields.io/badge/status-in_development-yellow?style=for-the-badge)
![Python](https://img.shields.io/badge/python-3.9+-blue?style=for-the-badge&logo=python)
![PyTorch](https://img.shields.io/badge/PyTorch-ee4c2c?style=for-the-badge&logo=pytorch&logoColor=white)
![React](https://img.shields.io/badge/React-20232a?style=for-the-badge&logo=react&logoColor=61dafb)

**[Demo]() Â· [Documentation]() Â· [Report Bug](https://github.com/jellyfish2346/grumpy-gamer/issues)**

</div>

---

## ğŸ§  What's This About?

**Grumpy Gamer** is a project to explore whether AI can beat classic games such as Wordle, Sudoku, and more. The goal is to implement game environments and develop AI agents that can play and potentially master these games using various algorithms, including rule-based logic, search, and machine learning. 

## Project Structure
- games/: Game environments (Wordle, Sudoku, etc.)
- agents/: AI agents for each game
- scripts/: Utilities to run experiments and evaluate agents
- tests/: Unit and integration tests
- docs/: Documentation and research notes

## âœ¨ Key Features

<table>
<tr>
<td width="50%">

### ğŸ¤– **Smart AI Agent**
- Learns through reinforcement learning
- Deep neural network decision-making  
- Thousands of hours of practice in minutes

</td>
<td width="50%">

### ğŸ¯ **Interactive Demo**
- Watch the AI play in real-time
- Challenge it yourself (good luck!)
- See inside its "brain" with visualizations

</td>
</tr>
<tr>
<td>

### ğŸ“Š **Training Dashboard**
- Live training metrics
- Performance graphs
- Compare different agents

</td>
<td>

### ğŸš€ **Full-Stack Application**
- Sleek React frontend
- Fast Python backend
- Deployed and ready to share

</td>
</tr>
</table>

## ğŸ› ï¸ Tech Stack
```ascii
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  Frontend:   React + TypeScript + Socket.io            â”‚
â”‚  Backend:    Python + FastAPI + WebSockets             â”‚
â”‚  ML Core:    PyTorch + Stable Baselines3               â”‚
â”‚  Game Env:   Gymnasium + gym-retro                     â”‚
â”‚  Database:   PostgreSQL + Redis                        â”‚
â”‚  Deploy:     Docker + Heroku/Vercel                    â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<details>
<summary><b>ğŸ“¦ Full Dependencies</b></summary>

**Backend:**
- ğŸ”¥ PyTorch - Deep learning framework
- ğŸ¯ Stable Baselines3 - RL algorithms (PPO, DQN, A2C)
- âš¡ FastAPI - Modern web framework
- ğŸ® Gymnasium - RL environment interface
- ğŸ•¹ï¸ gym-retro - Classic game environments

**Frontend:**
- âš›ï¸ React - UI framework
- ğŸ“˜ TypeScript - Type safety
- ğŸ”Œ Socket.io - Real-time communication
- ğŸ“ˆ Chart.js - Data visualization
- ğŸ¨ Tailwind CSS - Styling

**Infrastructure:**
- ğŸ³ Docker - Containerization
- ğŸ—„ï¸ PostgreSQL - Data storage
- âš¡ Redis - Caching
- â˜ï¸ Heroku/Vercel - Deployment

</details>

## ğŸ¯ Project Roadmap
```mermaid
graph LR
    A[ğŸ® Choose Game] --> B[ğŸ—ï¸ Setup Environment]
    B --> C[ğŸ§  Train Agent]
    C --> D[ğŸ¨ Build Frontend]
    D --> E[ğŸ”— Integrate Backend]
    E --> F[ğŸš€ Deploy]
    F --> G[ğŸ‰ Show Off!]
```

- [x] Choose tech stack
- [x] Initialize repository
- [ ] Set up development environment
- [ ] Implement RL training pipeline
- [ ] Train first successful agent
- [ ] Build React frontend
- [ ] Create FastAPI backend with WebSocket support
- [ ] Design training metrics dashboard
- [ ] Implement human vs AI gameplay
- [ ] Add model comparison features
- [ ] Write comprehensive documentation
- [ ] Deploy to production
- [ ] Create demo video

## ğŸš€ Quick Start
```bash
# Clone the repository
git clone https://github.com/jellyfish2346/grumpy-gamer.git
cd grumpy-gamer

# Setup coming soon! ğŸ—ï¸
```

## ğŸ® How It Works

<div align="center">
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Game State  â”‚
â”‚   (pixels)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Neural Net   â”‚  â† Learns from experience
â”‚  (AI Brain)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Actions    â”‚  â†’ Joystick movements
â”‚ (Up/Down/etc)â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Reward     â”‚  â†’ Did we win? +1 : -1
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ Repeat 1,000,000 times
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚
                  â–¼
            ğŸ† Pro Gamer
```

</div>

The AI uses **Proximal Policy Optimization (PPO)** to learn optimal gameplay strategies. It starts random, fails hilariously, then gradually discovers winning tactics through millions of attempts. Think of it as speed-running human childhood gaming experience.

## ğŸ¨ Screenshots

> Coming soon! The AI is still learning not to run into walls...

## ğŸ“ˆ Performance

| Metric | Human Average | Grumpy Gamer |
|--------|--------------|--------------|
| High Score | TBD | ğŸš§ Training... |
| Win Rate | TBD | ğŸš§ Training... |
| Rage Quits | High ğŸ˜¤ | Zero ğŸ˜ |

## ğŸ¤ Contributing

This is a portfolio project, but feel free to:
- ğŸ› Report bugs
- ğŸ’¡ Suggest features  
- â­ Star the repo if you think it's cool!

## ğŸ“ License

MIT Â© [Faizan Khan]

---

<div align="center">

**Built with ğŸ§  and lots of â˜•**

*"The AI doesn't get frustrated, which makes it inherently better than me at gaming"*

[â¬† Back to Top](#-grumpy-gamer)

</div>
